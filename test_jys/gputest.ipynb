{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cpu\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__) # torch 버전\n",
    "print(torch.version.cuda) # cuda 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3889,  0.0903,  0.3355,  1.4204, -1.2362],\n",
      "        [ 1.0803,  0.6316,  0.0809, -0.4822, -0.3039],\n",
      "        [ 2.7431, -0.7746, -2.1266, -0.4472,  0.8016],\n",
      "        [ 0.6726, -1.5422,  0.5993, -0.8714,  0.3406]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Bilinear 계층 정의\n",
    "bilinear = nn.Bilinear(in1_features=5, in2_features=10, out_features=3)\n",
    "\n",
    "# 입력 텐서 생성\n",
    "x1 = torch.randn(4, 5)  # 첫 번째 입력 (배치 크기: 4, 특징 차원: 5)\n",
    "x2 = torch.randn(4, 10) # 두 번째 입력 (배치 크기: 4, 특징 차원: 10)\n",
    "\n",
    "# 빌리니어 연산 수행\n",
    "output = bilinear(x1, x2)\n",
    "print(x1)\n",
    "print(output.shape)  # torch.Size([4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.5852,  0.2958],\n",
      "         [-0.2399, -0.6740]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "B = nn.Bilinear(2, 2, 1)\n",
    "print(B.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5216], grad_fn=<AddBackward0>)\n",
      "tensor([0.5216], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(B(torch.ones(2), torch.zeros(2)))\n",
    "print(B(torch.zeros(2), torch.ones(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.3297, -0.3921],\n",
      "         [ 0.0159,  0.2201]]], requires_grad=True)\n",
      "['T_destination', '__annotations__', '__call__', '__class__', '__constants__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'bfloat16', 'bias', 'buffers', 'call_super_init', 'children', 'compile', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'in1_features', 'in2_features', 'ipu', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'out_features', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'reset_parameters', 'set_extra_state', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'weight', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "B = nn.Bilinear(2, 2, 1, bias=False)\n",
    "A = B.weight\n",
    "print(A)\n",
    "print(dir(B))\n",
    "# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.zeros((3,1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b = torch.zeros(1)\n",
    "\n",
    "print(B(x_ones, x_zeros))\n",
    "# > tensor([0.], grad_fn=<ThAddBackward>)\n",
    "print(manual_bilinear(x_ones.view(1, 2), x_zeros.view(2, 1), A.squeeze(), b))\n",
    "# > tensor([0.], grad_fn=<ThAddBackward>)\n",
    "\n",
    "print(B(x_ones, x_ones))\n",
    "# > tensor([-0.7897], grad_fn=<ThAddBackward>)\n",
    "print(manual_bilinear(x_ones.view(1, 2), x_ones.view(2, 1), A.squeeze(), b))\n",
    "# > tensor([[-0.7897]], grad_fn=<ThAddBackward>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) # torch 버전\n",
    "print(torch.version.cuda) # cuda 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HeavyAtomCount'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esol = ['MinEStateIndex', 'MinPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2',\n",
    "        'FpDensityMorgan3', 'BCUT2D_CHGHI', 'SMR_VSA5', 'SlogP_VSA2', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA8',\n",
    "        'EState_VSA9', 'VSA_EState7', 'HeavyAtomCount', 'NumAromaticHeterocycles', 'NumHAcceptors', 'RingCount',\n",
    "        'MolMR', 'fr_C_O_noCOO']\n",
    "logvp = ['qed', 'MolWt', 'Kappa2', 'PEOE_VSA12', 'SlogP_VSA1', 'TPSA', 'EState_VSA1', 'EState_VSA10', 'VSA_EState1',\n",
    "         'VSA_EState6', 'VSA_EState8', 'HeavyAtomCount', 'NumAliphaticRings', 'NumSaturatedRings', 'fr_Ar_NH',\n",
    "         'fr_COO2', 'fr_azo', 'fr_benzene', 'fr_methoxy', 'fr_pyridine']\n",
    "\n",
    "set(esol) & set(logvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BCUT2D_CHGHI',\n",
       " 'EState_VSA9',\n",
       " 'FpDensityMorgan2',\n",
       " 'MinAbsPartialCharge',\n",
       " 'MinEStateIndex',\n",
       " 'NumAromaticHeterocycles',\n",
       " 'SlogP_VSA5',\n",
       " 'SlogP_VSA8',\n",
       " 'VSA_EState7',\n",
       " 'fr_C_O_noCOO'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['MinPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan3', 'SMR_VSA5', 'SlogP_VSA2', 'SlogP_VSA6', 'HeavyAtomCount', 'NumHAcceptors', 'RingCount', 'MolMR']\n",
    "b = ['MinEStateIndex', 'MinPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'BCUT2D_CHGHI', 'SMR_VSA5', 'SlogP_VSA2', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA8', 'EState_VSA9', 'VSA_EState7', 'HeavyAtomCount', 'NumAromaticHeterocycles', 'NumHAcceptors', 'RingCount', 'MolMR', 'fr_C_O_noCOO']\n",
    "set(b) - set(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fr_benzene', 'VSA_EState8'} \n",
      "\n",
      "{'VSA_EState6', 'VSA_EState1'} \n",
      "\n",
      "{'fr_COO2', 'MolWt', 'EState_VSA1'} \n",
      "\n",
      "{'fr_pyridine', 'PEOE_VSA12', 'qed', 'fr_methoxy', 'fr_azo', 'SlogP_VSA1', 'NumSaturatedRings', 'fr_Ar_NH', 'Kappa2', 'NumAliphaticRings'}\n"
     ]
    }
   ],
   "source": [
    "# logvp\n",
    "a_3 = ['TPSA', 'EState_VSA10', 'HeavyAtomCount']\n",
    "a_5 = ['TPSA', 'EState_VSA10', 'VSA_EState8', 'HeavyAtomCount', 'fr_benzene']\n",
    "a_7 = ['TPSA', 'EState_VSA10', 'VSA_EState1', 'VSA_EState6', 'VSA_EState8', 'HeavyAtomCount', 'fr_benzene']\n",
    "a_10 = ['MolWt', 'TPSA', 'EState_VSA1', 'EState_VSA10', 'VSA_EState1', 'VSA_EState6', 'VSA_EState8', 'HeavyAtomCount', 'fr_COO2', 'fr_benzene']\n",
    "a_20 = ['qed', 'MolWt', 'Kappa2', 'PEOE_VSA12', 'SlogP_VSA1', 'TPSA', 'EState_VSA1', 'EState_VSA10', 'VSA_EState1', 'VSA_EState6', 'VSA_EState8', 'HeavyAtomCount', 'NumAliphaticRings', 'NumSaturatedRings', 'fr_Ar_NH', 'fr_COO2', 'fr_azo', 'fr_benzene', 'fr_methoxy', 'fr_pyridine']\n",
    "\n",
    "print(set(a_5) - set(a_3), '\\n')\n",
    "print(set(a_7) - set(a_5), '\\n')\n",
    "print(set(a_10) - set(a_7), '\\n')\n",
    "print(set(a_20) - set(a_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Chi1n', 'Chi1v', 'Chi0v'} \n",
      "\n",
      "{'MaxPartialCharge', 'Kappa2'} \n",
      "\n",
      "{'SlogP_VSA4', 'EState_VSA9'} \n",
      "\n",
      "{'VSA_EState2', 'PEOE_VSA4', 'SlogP_VSA3'} \n",
      "\n",
      "{'BCUT2D_MRLOW', 'PEOE_VSA11', 'SlogP_VSA8', 'EState_VSA7', 'fr_Ndealkylation1', 'SMR_VSA5', 'fr_epoxide', 'fr_NH1', 'VSA_EState7'}\n"
     ]
    }
   ],
   "source": [
    "# qm7\n",
    "qm7_3 = ['Chi0v', 'Chi1n', 'Chi1v'] \n",
    "qm7_5 = ['MaxPartialCharge', 'Chi0v', 'Chi1n', 'Chi1v', 'Kappa2']\n",
    "qm7_7 = ['MaxPartialCharge', 'Chi0v', 'Chi1n', 'Chi1v', 'Kappa2', 'SlogP_VSA4', 'EState_VSA9']\n",
    "qm7_10 = ['MaxPartialCharge', 'Chi0v', 'Chi1n', 'Chi1v', 'Kappa2', 'PEOE_VSA4', 'SlogP_VSA3', 'SlogP_VSA4', 'EState_VSA9', 'VSA_EState2']\n",
    "qm7_20 = ['MaxPartialCharge', 'BCUT2D_MRLOW', 'Chi0v', 'Chi1n', 'Chi1v', 'Kappa2', 'PEOE_VSA11', 'PEOE_VSA4', 'SMR_VSA5', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA8', 'EState_VSA7', 'EState_VSA9', 'VSA_EState2', 'VSA_EState7', 'fr_NH1', 'fr_Ndealkylation1', 'fr_epoxide']\n",
    "\n",
    "print(set(qm7_3), '\\n')\n",
    "print(set(qm7_5) - set(qm7_3), '\\n')\n",
    "print(set(qm7_7) - set(qm7_5), '\\n')\n",
    "print(set(qm7_10) - set(qm7_7), '\\n')\n",
    "print(set(qm7_20) - set(qm7_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HeavyAtomCount', 'Chi0', 'Chi0v'} \n",
      "\n",
      "{'TPSA', 'fr_Al_OH'} \n",
      "\n",
      "{'NumHAcceptors', 'Chi4v'} \n",
      "\n",
      "{'NumRotatableBonds', 'BCUT2D_CHGHI', 'SMR_VSA9'} \n",
      "\n",
      "{'BertzCT', 'PEOE_VSA4', 'Kappa1', 'NumSaturatedCarbocycles', 'MolLogP', 'BalabanJ', 'SlogP_VSA10', 'VSA_EState4', 'VSA_EState7', 'fr_Ar_OH'}\n"
     ]
    }
   ],
   "source": [
    "# qm9\n",
    "qm9_3 = ['Chi0', 'Chi0v', 'HeavyAtomCount']\n",
    "qm9_5 = ['Chi0', 'Chi0v', 'TPSA', 'HeavyAtomCount', 'fr_Al_OH']\n",
    "qm9_7 = ['Chi0', 'Chi0v', 'Chi4v', 'TPSA', 'HeavyAtomCount', 'NumHAcceptors', 'fr_Al_OH']\n",
    "qm9_10 = ['BCUT2D_CHGHI', 'Chi0', 'Chi0v', 'Chi4v', 'SMR_VSA9', 'TPSA', 'HeavyAtomCount', 'NumHAcceptors', 'NumRotatableBonds', 'fr_Al_OH']\n",
    "qm9_20 = ['BCUT2D_CHGHI', 'BalabanJ', 'BertzCT', 'Chi0', 'Chi0v', 'Chi4v', 'Kappa1', 'PEOE_VSA4', 'SMR_VSA9', 'SlogP_VSA10', 'TPSA', 'VSA_EState4', 'VSA_EState7', 'HeavyAtomCount', 'NumHAcceptors', 'NumRotatableBonds', 'NumSaturatedCarbocycles', 'MolLogP', 'fr_Al_OH', 'fr_Ar_OH']\n",
    "\n",
    "print(set(qm9_3), '\\n')\n",
    "print(set(qm9_5) - set(qm9_3), '\\n')\n",
    "print(set(qm9_7) - set(qm9_5), '\\n')\n",
    "print(set(qm9_10) - set(qm9_7), '\\n')\n",
    "print(set(qm9_20) - set(qm9_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "CUDA device count: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"CUDA device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\Anaconda\\envs\\egcn\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGL version: 2.2.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "print(\"DGL version:\", dgl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.1.0+cu121\n",
      "cuda version: 12.1\n",
      "Is CUDA available: True\n",
      "CUDA device count: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "print(\"torch version:\", torch.__version__) # torch 버전\n",
    "print(\"cuda version:\", torch.version.cuda) # cuda 버전\n",
    "\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"CUDA device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
